{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49a8736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxi7524/repositories/SAD2_final_project\n",
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    }
   ],
   "source": [
    "# package for managing experiments\n",
    "from sad2_final_project.analysis import BooleanNetworkExperiment\n",
    "# system packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# paths\n",
    "## set global dir\n",
    "cwd=Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    os.chdir(cwd.parent) \n",
    "print(os.getcwd())\n",
    "\n",
    "## create paths \n",
    "DATA_PATH = Path('data')\n",
    "## create directories\n",
    "!mkdir {DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce4c2c",
   "metadata": {},
   "source": [
    "## Part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1fb6d",
   "metadata": {},
   "source": [
    "### Numerical analysis of Bnfinder\n",
    "#### Task\n",
    "Construct several Boolean networks with sizes (measured by the number of nodes or variables) ranging from 5 to 16.† Each node should have no more than three parent nodes, and the Boolean functions governing individual nodes should be generated at random.\n",
    "\n",
    "#### Goal\n",
    "The goal of this study is to determine how the type and amount of time-series data generated from Boolean network dynamics affect the accuracy of dynamic Bayesian network (DBN) structure inference. In particular, we aim to identify:\n",
    "- how the presence of attractor states in trajectories influences reconstruction accuracy,\n",
    "- how trajectory length, sampling frequency, and the number of trajectories affects model metrics\n",
    "- how these effects depend on network size and update dynamics,\n",
    "- which data-generation techniques yield stable and informative reconstructions. \n",
    "\n",
    "---\n",
    "\n",
    "#### Sets\n",
    "\n",
    "To ensure reproducibility and comparisons, experiments are organized into predefined sets.\n",
    "##### Groups\n",
    "1. **Network size groups**\n",
    "   Networks are grouped by number of nodes (every 2 from 4 to 16) to analyze scaling behavior.\n",
    "2. **Update mode groups**\n",
    "   Synchronous and asynchronous updates are treated separately, as they correspond to different stochastic processes (deterministic map vs stochastic transition system).\n",
    "   <!-- sprawdzić  -->\n",
    "3. **Scoring function groups**\n",
    "<!-- TODO MICHAŁ: tutaj rozwiną o scoring functions -->\n",
    "   MDL and BDe are analyzed independently. Absolute score values are not compared across scoring functions; only trends with respect to accuracy are considered.\n",
    "4. **Random function sets**\n",
    "   For each experimental condition, multiple independently generated Boolean networks are used.\n",
    "   Random seeds are fixed per network/experiment (TODO ?) instance so that different data-generation parameters (sampling frequency, trajectory length, number of trajectories) are evaluated on identical underlying networks.\n",
    "   <!-- is not possible we just need to use seed to experiments are reproducle -->\n",
    "\n",
    "---\n",
    "\n",
    "##### Averaging and Distributions\n",
    "\n",
    "All reported results are based on **distributions**, not single values.\n",
    "Depending on the experiment, averaging is performed over:\n",
    "\n",
    "- trajectories (within a dataset),\n",
    "- independent datasets,\n",
    "- independently generated networks.\n",
    "\n",
    "The aggregation strategy is explicitly chosen for each experiment to match the source of variability under investigation.\n",
    "\n",
    "\n",
    "<!-- ### Impact of Proportion of Attractor States in Trajectories\n",
    "\n",
    "**Objective.**\n",
    "To quantify how an increasing proportion of attractor states in trajectories affects the sensitivity of network structure reconstruction.\n",
    "\n",
    "The central hypothesis is that a high proportion of attractor states leads to strong temporal autocorrelation, which **reduces the effective number of independent observations**, thereby decreasing the sensitivity (recall) of detected edges in the inferred network.\n",
    "\n",
    "**Experimental design.**\n",
    "\n",
    "- For each network, datasets are generated with controlled proportions of attractor states:\n",
    "  (0%, 10%, \\ldots, 100%).\n",
    "- Trajectories are made sufficiently long to ensure that attractors are reached whenever the target proportion is nonzero.\n",
    "- Sampling frequency is varied to contrast regimes of strong versus weak temporal dependence.\n",
    "\n",
    "**Autocorrelation analysis.**\n",
    "For each dataset, temporal dependence is quantified using the **autocorrelation function (ACF)**:\n",
    "[\n",
    "\\rho(k) = \\frac{\\mathrm{Cov}(X_t, X_{t+k})}{\\mathrm{Var}(X_t)}\n",
    "]\n",
    "computed separately for each node and then aggregated (mean or maximum across nodes).\n",
    "\n",
    "From the ACF, the **effective sample size (ESS)** is estimated:\n",
    "[\n",
    "\\mathrm{ESS} \\approx \\frac{N}{1 + 2\\sum_{k=1}^{K} \\rho(k)},\n",
    "]\n",
    "where (N) is the nominal number of observations and (K) is the truncation lag where autocorrelation becomes negligible.\n",
    "\n",
    "Reconstruction accuracy is then analyzed as a function of ESS rather than nominal sample size.\n",
    "\n",
    "**Rationale.**\n",
    "This isolates the effect of attractor-induced redundancy and avoids conflating “amount of data” with “amount of information”. -->\n",
    "\n",
    "---\n",
    "\n",
    "#### Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413d9d0",
   "metadata": {},
   "source": [
    "##### 1. Relation Between Trajectory Length and Entering Attractors\n",
    "\n",
    "**Objective.**\n",
    "To characterize how trajectory length is related to the probability of entering attractors as a function of network size and dynamics.\n",
    "\n",
    "**Experimental design.**\n",
    "\n",
    "- The target attractor proportion is **not controlled**; trajectories evolve naturally.\n",
    "- Trajectory lengths are varied in increments proportional to network size:\n",
    "    - from 5 steps to 50 by 5\n",
    "    - from 50 steps to 200 by 10\n",
    "- Networks are grouped by size (from 4 to 16 nodes, in steps of two).\n",
    "- The number of parents per node is randomly chosen from set of $\\{1,2,3\\}$ to avoid conditioning results on a fixed connectivity pattern.\n",
    "\n",
    "**Measured quantities.**\n",
    "\n",
    "- Probability of reaching an attractor as a function of trajectory length.\n",
    "- How different groups (below TODO - inner link) differ in in this probability.\n",
    "\n",
    "**Rationale.**\n",
    "Attractor entry is an emergent property of the dynamics. Controlling it directly is undesirable, as it would introduce selection bias. This experiment instead characterizes the **natural scaling behavior** of Boolean network dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43ec6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "NUM_NODES = [i for i in range(4, 17, 2)] # od 4 do 16 (włącznie) wierzchołków, co dwie krawędzie\n",
    "SCORE_FUNCTIONS = [\"MDL\", \"BDE\"]\n",
    "UPDATE_MODE = [\"synchronous\", \"asynchronous\"]\n",
    "N_PARENT_PER_NODE = [[1, 2, 3]]\n",
    "N_REPETITIONS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed694ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_nodes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "update_mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trajectory_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_trajectories",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sampling_frequency",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "score_function",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_parents_per_node",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "rep_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "condition_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6f5a8cf0-d8fe-4878-893f-ae18b8b0fd89",
       "rows": [
        [
         "0",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "0",
         "0000"
        ],
        [
         "1",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "1",
         "0001"
        ],
        [
         "2",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "2",
         "0002"
        ],
        [
         "3",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "3",
         "0003"
        ],
        [
         "4",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "4",
         "0004"
        ],
        [
         "5",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "5",
         "0005"
        ],
        [
         "6",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "6",
         "0006"
        ],
        [
         "7",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "7",
         "0007"
        ],
        [
         "8",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "8",
         "0008"
        ],
        [
         "9",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "9",
         "0009"
        ],
        [
         "10",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "10",
         "0010"
        ],
        [
         "11",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "11",
         "0011"
        ],
        [
         "12",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "12",
         "0012"
        ],
        [
         "13",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "13",
         "0013"
        ],
        [
         "14",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "14",
         "0014"
        ],
        [
         "15",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "15",
         "0015"
        ],
        [
         "16",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "16",
         "0016"
        ],
        [
         "17",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "17",
         "0017"
        ],
        [
         "18",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "18",
         "0018"
        ],
        [
         "19",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "19",
         "0019"
        ],
        [
         "20",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "20",
         "0020"
        ],
        [
         "21",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "21",
         "0021"
        ],
        [
         "22",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "22",
         "0022"
        ],
        [
         "23",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "23",
         "0023"
        ],
        [
         "24",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "24",
         "0024"
        ],
        [
         "25",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "25",
         "0025"
        ],
        [
         "26",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "26",
         "0026"
        ],
        [
         "27",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "27",
         "0027"
        ],
        [
         "28",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "28",
         "0028"
        ],
        [
         "29",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "MDL",
         "[1, 2, 3]",
         "29",
         "0029"
        ],
        [
         "30",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "0",
         "0030"
        ],
        [
         "31",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "1",
         "0031"
        ],
        [
         "32",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "2",
         "0032"
        ],
        [
         "33",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "3",
         "0033"
        ],
        [
         "34",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "4",
         "0034"
        ],
        [
         "35",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "5",
         "0035"
        ],
        [
         "36",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "6",
         "0036"
        ],
        [
         "37",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "7",
         "0037"
        ],
        [
         "38",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "8",
         "0038"
        ],
        [
         "39",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "9",
         "0039"
        ],
        [
         "40",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "10",
         "0040"
        ],
        [
         "41",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "11",
         "0041"
        ],
        [
         "42",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "12",
         "0042"
        ],
        [
         "43",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "13",
         "0043"
        ],
        [
         "44",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "14",
         "0044"
        ],
        [
         "45",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "15",
         "0045"
        ],
        [
         "46",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "16",
         "0046"
        ],
        [
         "47",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "17",
         "0047"
        ],
        [
         "48",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "18",
         "0048"
        ],
        [
         "49",
         "4",
         "synchronous",
         "20",
         "50",
         "2",
         "BDE",
         "[1, 2, 3]",
         "19",
         "0049"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 30240
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>update_mode</th>\n",
       "      <th>trajectory_length</th>\n",
       "      <th>n_trajectories</th>\n",
       "      <th>sampling_frequency</th>\n",
       "      <th>score_function</th>\n",
       "      <th>n_parents_per_node</th>\n",
       "      <th>rep_id</th>\n",
       "      <th>condition_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>synchronous</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>MDL</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>synchronous</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>MDL</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>synchronous</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>MDL</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>synchronous</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>MDL</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>synchronous</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>MDL</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>4</td>\n",
       "      <td>0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30235</th>\n",
       "      <td>16</td>\n",
       "      <td>asynchronous</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>BDE</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>25</td>\n",
       "      <td>30235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30236</th>\n",
       "      <td>16</td>\n",
       "      <td>asynchronous</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>BDE</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>26</td>\n",
       "      <td>30236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30237</th>\n",
       "      <td>16</td>\n",
       "      <td>asynchronous</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>BDE</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>27</td>\n",
       "      <td>30237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30238</th>\n",
       "      <td>16</td>\n",
       "      <td>asynchronous</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>BDE</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>28</td>\n",
       "      <td>30238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30239</th>\n",
       "      <td>16</td>\n",
       "      <td>asynchronous</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>BDE</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>29</td>\n",
       "      <td>30239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30240 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_nodes   update_mode  trajectory_length  n_trajectories  \\\n",
       "0              4   synchronous                 20              50   \n",
       "1              4   synchronous                 20              50   \n",
       "2              4   synchronous                 20              50   \n",
       "3              4   synchronous                 20              50   \n",
       "4              4   synchronous                 20              50   \n",
       "...          ...           ...                ...             ...   \n",
       "30235         16  asynchronous                100              50   \n",
       "30236         16  asynchronous                100              50   \n",
       "30237         16  asynchronous                100              50   \n",
       "30238         16  asynchronous                100              50   \n",
       "30239         16  asynchronous                100              50   \n",
       "\n",
       "       sampling_frequency score_function n_parents_per_node  rep_id  \\\n",
       "0                       2            MDL          [1, 2, 3]       0   \n",
       "1                       2            MDL          [1, 2, 3]       1   \n",
       "2                       2            MDL          [1, 2, 3]       2   \n",
       "3                       2            MDL          [1, 2, 3]       3   \n",
       "4                       2            MDL          [1, 2, 3]       4   \n",
       "...                   ...            ...                ...     ...   \n",
       "30235                   5            BDE          [1, 2, 3]      25   \n",
       "30236                   5            BDE          [1, 2, 3]      26   \n",
       "30237                   5            BDE          [1, 2, 3]      27   \n",
       "30238                   5            BDE          [1, 2, 3]      28   \n",
       "30239                   5            BDE          [1, 2, 3]      29   \n",
       "\n",
       "      condition_id  \n",
       "0             0000  \n",
       "1             0001  \n",
       "2             0002  \n",
       "3             0003  \n",
       "4             0004  \n",
       "...            ...  \n",
       "30235        30235  \n",
       "30236        30236  \n",
       "30237        30237  \n",
       "30238        30238  \n",
       "30239        30239  \n",
       "\n",
       "[30240 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create experiments:\n",
    "## case: Relation between trajectory length and entering attractors\n",
    "exp_trajectory_length = BooleanNetworkExperiment(\n",
    "    ### paths\n",
    "    data_path=DATA_PATH,\n",
    "    experiment_name='trajectory_length_vs_attractors',\n",
    "    \n",
    "    ### Tested variables \n",
    "    trajectory_length=list(range(20, 101, 10)),\n",
    "    n_trajectories=[50],\n",
    "    sampling_frequency=[2, 3, 4, 5],\n",
    "\n",
    "    ### Constant values per experiment \n",
    "    n_repetitions=30,\n",
    "    n_parents_per_node=N_PARENT_PER_NODE,\n",
    "\n",
    "    ### Groups (bo wszędzie takie same)\n",
    "    num_nodes=NUM_NODES,\n",
    "    score_functions = SCORE_FUNCTIONS,\n",
    "    update_mode=UPDATE_MODE,\n",
    "\n",
    "    simulate_trajectories_to_csv_kwargs = {\n",
    "            # \"sampling_frequency\": 1,\n",
    "            \"target_attractor_ratio\": 0.5,  # Approximate fraction of trajectory in attractor (0-1)\n",
    "            \"tolerance\": 0.5,               # Allowed deviation from the calculated entrance step (0-1)\n",
    "        }\n",
    ") \n",
    "exp_trajectory_length.show_experiment_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ca7d77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0000.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0001.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0002.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0003.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0004.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0005.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0006.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0007.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0008.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0009.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0010.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0011.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0012.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0013.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0014.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0015.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0016.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0017.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0018.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0019.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0020.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0021.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0022.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0023.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0024.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0025.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0026.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0027.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0028.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0029.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0030.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0031.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0032.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0033.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0034.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0035.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0036.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0037.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0038.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0039.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0040.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0041.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0042.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0043.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0044.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0045.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0046.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0047.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0048.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0049.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0050.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0051.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0052.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0053.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0054.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0055.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0056.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0057.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0058.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0059.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0060.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0061.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0062.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0063.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0064.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0065.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0066.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0067.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0068.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0069.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0070.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0071.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0072.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0073.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0074.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0075.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0076.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0077.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0078.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0079.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0080.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0081.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0082.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0083.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0084.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0085.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0086.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0087.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0088.csv NOT created (requirements not met). Skipping inference.\n",
      "[INFO] Dataset data/trajectory_length_vs_attractors/datasets/0089.csv NOT created (requirements not met). Skipping inference.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mexp_trajectory_length\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/SAD2_final_project/src/sad2_final_project/analysis/experiment.py:269\u001b[39m, in \u001b[36mBooleanNetworkExperiment.run_experiment\u001b[39m\u001b[34m(self, n_jobs, subset)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_single_condition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    270\u001b[39m             success_count += \u001b[32m1\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/SAD2_final_project/src/sad2_final_project/analysis/experiment.py:213\u001b[39m, in \u001b[36mBooleanNetworkExperiment._run_single_condition\u001b[39m\u001b[34m(self, row)\u001b[39m\n\u001b[32m    209\u001b[39m bn.save_ground_truth(gt_path)\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# ---------- 3. generate data ----------\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# oznaczamy czy wygenerowany dataset powiódł sie sukcesem (potrzebne do zliczania sukcesów i jeżeli brak sukcesu nie próbujemy uruchamiać bnfindera bo brak pliku)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m success = \u001b[43msimulate_trajectories_to_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbn_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_trajectories\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_trajectories\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_frequency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msampling_frequency\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrajectory_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrajectory_length\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimulate_trajectories_to_csv_kwargs\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[INFO] Dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m NOT created (requirements not met). Skipping inference.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/SAD2_final_project/src/sad2_final_project/boolean_bn/bn_sampling.py:79\u001b[39m, in \u001b[36msimulate_trajectories_to_csv\u001b[39m\u001b[34m(bn_instance, num_trajectories, output_file, sampling_frequency, trajectory_length, target_attractor_ratio, tolerance)\u001b[39m\n\u001b[32m     75\u001b[39m max_total_states = num_trajectories * trajectory_length\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m traj_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_trajectories):\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     trajectory, att_count, trans_count = \u001b[43mbn_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimulate_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43msampling_frequency\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrajectory_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrajectory_length\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# print(att_count, trans_count)\u001b[39;00m\n\u001b[32m     84\u001b[39m     traj_total = att_count + trans_count\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/SAD2_final_project/src/sad2_final_project/boolean_bn/bn.py:362\u001b[39m, in \u001b[36mBN.simulate_trajectory\u001b[39m\u001b[34m(self, sampling_frequency, trajectory_length)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, total_steps):\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33msynchronous\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         next_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_synchronous\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    364\u001b[39m         coordinate = random.randint(\u001b[32m0\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_nodes - \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/SAD2_final_project/src/sad2_final_project/boolean_bn/bn.py:140\u001b[39m, in \u001b[36mBN._next_synchronous\u001b[39m\u001b[34m(self, curr_state)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# x(t+1) = (f1, f2,...,fn) evaluates each function on corresponding coordinate\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     new_state = [\u001b[38;5;28mself\u001b[39m.TF[\u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimplify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.functions]\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/SAD2_final_project/.venv/lib/python3.13/site-packages/boolean/boolean.py:1333\u001b[39m, in \u001b[36mDualBase.simplify\u001b[39m\u001b[34m(self, sort)\u001b[39m\n\u001b[32m   1329\u001b[39m args = [arg.simplify() \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args]\n\u001b[32m   1331\u001b[39m \u001b[38;5;66;03m# Create new instance of own class with canonical args.\u001b[39;00m\n\u001b[32m   1332\u001b[39m \u001b[38;5;66;03m# TODO: Only create new class if some args changed.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m expr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[38;5;66;03m# Literalize before doing anything, this also applies De Morgan's Law\u001b[39;00m\n\u001b[32m   1336\u001b[39m expr = expr.literalize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/SAD2_final_project/.venv/lib/python3.13/site-packages/boolean/boolean.py:1657\u001b[39m, in \u001b[36mOR.__init__\u001b[39m\u001b[34m(self, arg1, arg2, *args)\u001b[39m\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1, arg2, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1658\u001b[39m     \u001b[38;5;28mself\u001b[39m.sort_order = \u001b[32m25\u001b[39m\n\u001b[32m   1659\u001b[39m     \u001b[38;5;28mself\u001b[39m.identity = \u001b[38;5;28mself\u001b[39m.FALSE\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/SAD2_final_project/.venv/lib/python3.13/site-packages/boolean/boolean.py:1250\u001b[39m, in \u001b[36mDualBase.__init__\u001b[39m\u001b[34m(self, arg1, arg2, *args)\u001b[39m\n\u001b[32m   1249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1, arg2, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1250\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDualBase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m     \u001b[38;5;66;03m# identity element for the specific operation.\u001b[39;00m\n\u001b[32m   1253\u001b[39m     \u001b[38;5;66;03m# This will be TRUE for the AND operation and FALSE for the OR operation.\u001b[39;00m\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28mself\u001b[39m.identity = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/SAD2_final_project/.venv/lib/python3.13/site-packages/boolean/boolean.py:1056\u001b[39m, in \u001b[36mFunction.__init__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# Specifies an infix notation of an operator for printing such as | or &.\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28mself\u001b[39m.operator = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mExpression\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBad arguments: all arguments must be an Expression: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28mself\u001b[39m.args = \u001b[38;5;28mtuple\u001b[39m(args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/SAD2_final_project/.venv/lib/python3.13/site-packages/boolean/boolean.py:1056\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# Specifies an infix notation of an operator for printing such as | or &.\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28mself\u001b[39m.operator = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(arg, Expression) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args\n\u001b[32m   1058\u001b[39m ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBad arguments: all arguments must be an Expression: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28mself\u001b[39m.args = \u001b[38;5;28mtuple\u001b[39m(args)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "exp_trajectory_length.run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab75a84",
   "metadata": {},
   "source": [
    "##### 2. Impact of Sampling Frequency\n",
    "\n",
    "**Objective.**\n",
    "To determine how temporal subsampling affects autocorrelation, effective sample size, and reconstruction accuracy.\n",
    "\n",
    "Dynamic Bayesian network inference assumes conditional independence of observations given parent states in the previous time slice. Excessive temporal dependence violates this assumption in practice by introducing redundant observations.\n",
    "\n",
    "**Experimental design.**\n",
    "\n",
    "- For fixed networks and trajectory lengths, datasets are generated using multiple sampling frequencies (1, 2, 3, 4, 5).\n",
    "- For each dataset\n",
    "    - ACF and ESS are computed,\n",
    "    - MDL and BDe scores are extracted from BNFinder2 logs,\n",
    "\n",
    "**Analysis.**\n",
    "Accuracy is analyzed jointly as a function of: \n",
    "<!-- What does it mean jointly ?? -->\n",
    "\n",
    "* sampling frequency,\n",
    "* ESS,\n",
    "* scoring function (MDL or BDe).\n",
    "\n",
    "**Rationale.**\n",
    "This experiment identifies sampling regimes that balance reduced autocorrelation against loss of dynamic information due to over-subsampling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create experiments:\n",
    "## case: Relation between trajectory length and entering attractors\n",
    "exp_trajectory_length = BooleanNetworkExperiment(\n",
    "    ### paths\n",
    "    data_path=DATA_PATH,\n",
    "    experiment_name='trajectory_length_vs_attractors',\n",
    "    \n",
    "    ### Tested variables \n",
    "    trajectory_length=list(range(50, 61, 10)),\n",
    "    n_trajectories=[50],\n",
    "    sampling_frequency=[1],\n",
    "\n",
    "    ### Constant values per experiment \n",
    "    n_repetitions=30,\n",
    "    n_parents_per_node=N_PARENT_PER_NODE\n",
    "\n",
    "    ### Groups (bo wszędzie takie same)\n",
    "    num_nodes=NUM_NODES,\n",
    "    score_functions = SCORE_FUNCTIONS\n",
    "    update_mode=UPDATE_MODE\n",
    "\n",
    "    simulate_trajectories_to_csv_kwargs = {\n",
    "            # \"sampling_frequency\": 1,\n",
    "            \"target_attractor_ratio\": 0.5,  # Approximate fraction of trajectory in attractor (0-1)\n",
    "            \"tolerance\": 0.5,               # Allowed deviation from the calculated entrance step (0-1)\n",
    "        }\n",
    ") \n",
    "exp_trajectory_length.show_experiment_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7557c21",
   "metadata": {},
   "source": [
    "##### 3. Amount of Trajectories Required for Stable Inference\n",
    "\n",
    "**Objective.**\n",
    "To determine how many independent trajectories are required to obtain statistically stable reconstructions.\n",
    "\n",
    "**Experimental design.**\n",
    "\n",
    "- Sampling frequency and trajectory length are fixed to values identified as near-optimal in previous experiments.\n",
    "- The number of trajectories per dataset is gradually increased - from 10 to 100 by 10.\n",
    "- For each setting, multiple (30) independent repetitions are performed to obtain convergent distribution .\n",
    "\n",
    "**Evaluation.**\n",
    "\n",
    "- Reconstruction accuracy is summarized using distributions (score functions).\n",
    "- Stability is assessed by observing convergence of accuracy metrics as the number of trajectories increases.\n",
    "- No classical parametric hypothesis test is assumed; instead, convergence trends is reported.\n",
    "<!-- Nie znalazłem żadnego sensownego -->\n",
    "\n",
    "**Rationale.**\n",
    "Due to the randomness of Boolean functions and initial states, averaging over multiple networks is necessary to separate systematic effects from instance-specific variability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54591308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create experiments:\n",
    "## case: Relation between trajectory length and entering attractors\n",
    "exp_trajectory_length = BooleanNetworkExperiment(\n",
    "    ### paths\n",
    "    data_path=DATA_PATH,\n",
    "    experiment_name='trajectory_length_vs_attractors',\n",
    "    \n",
    "    ### Tested variables \n",
    "    trajectory_length=list(range(50, 61, 10)),\n",
    "    n_trajectories=[50],\n",
    "    sampling_frequency=[1],\n",
    "\n",
    "    ### Constant values per experiment \n",
    "    n_repetitions=30,\n",
    "    n_parents_per_node=N_PARENT_PER_NODE\n",
    "\n",
    "    ### Groups (bo wszędzie takie same)\n",
    "    num_nodes=NUM_NODES,\n",
    "    score_functions = SCORE_FUNCTIONS\n",
    "    update_mode=UPDATE_MODE\n",
    "\n",
    "    simulate_trajectories_to_csv_kwargs = {\n",
    "            # \"sampling_frequency\": 1,\n",
    "            \"target_attractor_ratio\": 0.5,  # Approximate fraction of trajectory in attractor (0-1)\n",
    "            \"tolerance\": 0.5,               # Allowed deviation from the calculated entrance step (0-1)\n",
    "        }\n",
    ") \n",
    "exp_trajectory_length.show_experiment_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e2f35",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALIZA - będziemy robić do wszystkie wstępny opis po co jakie ploty i potem robić ploty i potem je omawiać "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d43249d",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0242e96d",
   "metadata": {},
   "source": [
    "### 1. Choose validated Boolean network\n",
    "#### Task\n",
    "our task is to consider a validated Boolean network model of a real-life biological mechanism. To this end, select a Boolean network 2 model of your choice from the ‘models’ subfolder of the Biodivine repository, available at https://github.com/sybila/biodivine-boolean-models, with the number of nodes (variables) not exceeding 16.‡. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da385766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54adb8e8",
   "metadata": {},
   "source": [
    "### 2. Generate dataset,\n",
    "#### Task\n",
    "Using the insights gained from the first part of the project,\n",
    "generate an appropriate dataset for the network inference task. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccee79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO MAX: raport - dataset i wnioski \n",
    "#  - tworzymy dataset (na bazie wniosków z poprzedniego)\n",
    "#  - tutaj bierzemy wszystkie datasety, jakie wnioski udało nam się ustalić do nich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace05165",
   "metadata": {},
   "source": [
    "### 3. Reconstruct the network with BNFinder2 \n",
    "#### Task\n",
    "Reconstruct the network structure with BNFinder2, applying a scoring function chosen based on your previous\n",
    "experience. Evaluate the accuracy of the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO MAX: raport zliczenie jakości dopasowania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302f058",
   "metadata": {},
   "source": [
    "Informacja do tych sieci do eksperymentów numerycznych\n",
    "- grupy\n",
    "    - synchroniczne / asynchroniczne\n",
    "    - ilość wierzchołków\n",
    "    - funkcje optymalizacji \n",
    "- zmienne latentne\n",
    "    - wpadania do atraktorów \n",
    "    - za\n",
    "- zmienne kontrolowane \n",
    "    - długość trajektorii \n",
    "    - ilość trajektorii \n",
    "    - ilość prób (do stworzenia rozkładu) \n",
    "- stałe\n",
    "    - ilość rodziców na wierzchołek, (to musi byc losowe, badanie tego typu jest pytaniem ilośc atraktorów $\\sim$ ilość rodziców - nie interesuje nas to)\n",
    "\n",
    "\n",
    "\n",
    "UWAGA\n",
    "- dodać flage to experimentu, z usuwaniem folderów (testow można puścić wtedy) \n",
    "\n",
    "Klasy do robienia analiz (osobne skrypty)\n",
    "- analysis\n",
    "    - klasa która przyjmuje metadane, oraz zintegrowane wyniki eksperymentu\n",
    "    - będzie ona robić wszystkie zliczenia grupowania itd. \n",
    "- visualization\n",
    "    - klasa która będzie brać klasę z analysis \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
