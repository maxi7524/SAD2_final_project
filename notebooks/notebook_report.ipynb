{
 "cells": [
  {
   "cell_type": "code",
   "id": "45d758ed",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sad2_final_project.analysis import add_missing_metrics_from_experiment, loader_obsolete_data, compute_wilcoxon_table, plot_wilcoxon_heatmap\n",
    "import os\n",
    "from sad2_final_project.analysis import plot_scatter, plot_boxplot, plot_scatter_subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "cwd=Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    os.chdir(cwd.parent)\n",
    "print(os.getcwd())\n",
    "## create paths\n",
    "DATA_PATH2 = Path('data/trajectory_length_vs_attractors1')\n",
    "DATA_PATHS = Path('data/analysis_3_synchronous_part_1')\n",
    "DATA_PATHA = Path('data/analysis_3_asynchronous_part_1')\n",
    "\n",
    "df = loader_obsolete_data(DATA_PATH2 / 'results/metadata.csv', DATA_PATH2 / 'results/joined_results_trajectory_length_vs_attractors.csv')\n",
    "# dfs = pd.read_csv(DATA_PATHS / 'results/metadata.csv')\n",
    "# dfa = pd.read_csv(DATA_PATHA / 'results/metadata.csv')\n",
    "dfs = loader_obsolete_data(DATA_PATHS / 'results/metadata.csv', DATA_PATHS / 'results/joined_results_analysis_3_synchronous.csv')\n",
    "dfa = loader_obsolete_data(DATA_PATHA / 'results/metadata.csv', DATA_PATHA / 'results/joined_results_analysis_3_asynchronous.csv')\n",
    "\n",
    "# print(dfs.columns)\n",
    "# print(dfa.columns)\n",
    "metrics_list=['TP', 'FP', 'FN', 'precision', 'recall', 'sensitivity', 'AHD', 'SHD', 'EHD', 'SID']\n",
    "df = add_missing_metrics_from_experiment(df, DATA_PATH2, metrics_list, after_column='attractor_ratio')\n",
    "dfs = add_missing_metrics_from_experiment(dfs, DATA_PATHS, metrics_list, after_column='attractor_ratio')\n",
    "dfa = add_missing_metrics_from_experiment(dfa, DATA_PATHA, metrics_list, after_column='attractor_ratio')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dc401a88",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "## Goal\n",
    "The goal of this study is to investigate the relation between **sampling strategy** and **model selection metrics** in *boolean Bayesian networks (BDNs)* using `BNFinder2`. \n",
    "\n",
    "In particular, we analyze how characteristics of time-series data generated from Boolean networks influence the accuracy of reconstructing the underlying network structure using Bayesian methods. The experimental factors under investigation include:\n",
    "- the **trajectory length**,\n",
    "- the **sampling frequency**, defined as selecting every $n$-th state along a trajectory,\n",
    "- the ratio between the **number of nodes** and the **trajectory length**, introduced as a normalization parameter $k$.\n",
    "\n",
    "The generated datasets are grouped into classes determined by:\n",
    "- the **update mode** (synchronous vs asynchronous),\n",
    "- the **scoring function** used during inference (MDL and BDe).\n",
    "\n",
    "In addition, we study **scaling relations with respect to the number of nodes**, aiming to characterize how data requirements and reconstruction accuracy change as network size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c639ad",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487eda0",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "### General reasoning \n",
    "The primary objective of the experimental design is to isolate how properties of sampled time-series data affect the accuracy of Boolean network reconstruction using `BNFinder2`. \n",
    "***\n",
    "### Update Mode\n",
    "We distinguish between two fundamentally different update mechanisms:\n",
    "- **Synchronous update**, which defines a deterministic dynamical system: from any given state, the successor state is uniquely determined.\n",
    "- **Asynchronous update**, which induces a stochastic process: at each time step, a randomly selected node is updated, leading to multiple possible successor states.\n",
    "This distinction is critical, as asynchronous dynamics introduce temporal dependence and potential autocorrelation in trajectories. In particular, long residence times in attractors or local cycles may reduce the effective information content of sampled data. Consequently, naive dense sampling may lead to strongly correlated observations, while aggressive subsampling may destroy causal ordering information.\n",
    "***\n",
    "### Scoring Functions\n",
    "We employ two scoring functions implemented in BNFinder2, which differ in how they trade off data fit against model complexity.\n",
    "Let $G$ denote a candidate network structure and $D$ the observed dataset.\n",
    "\n",
    "**Minimal Description Length (MDL)**\n",
    "\n",
    "The MDL score is defined as\n",
    "$$\n",
    "\\mathrm{MDL}(G \\mid D)\n",
    "= - \\log P(D \\mid G, \\hat{\\theta})\n",
    "\\times \\frac{1}{2} , |\\theta_G| , \\log |D|,\n",
    "$$\n",
    "\n",
    "\n",
    "where $\\hat{\\theta}$ are maximum-likelihood parameters and $|\\theta_G|$ denotes the number of free parameters implied by the graph structure $G$.\n",
    "\n",
    "The first term rewards goodness of fit, while the second term penalizes model complexity. As a consequence, MDL favors simpler graphs when data are scarce and becomes less restrictive as sample size increases. This makes MDL particularly sensitive to undersampling and normalization effects.\n",
    "\n",
    "**Bayesian–Dirichlet equivalence (BDe)**\n",
    "\n",
    "The BDe score evaluates the marginal likelihood\n",
    "\n",
    "$$\n",
    "\\mathrm{BDe}(G \\mid D)\n",
    "= \\log \\int P(D \\mid G, \\theta), P(\\theta \\mid G), d\\theta,\n",
    "$$\n",
    "\n",
    "assuming a Dirichlet prior over conditional probability tables. Under standard assumptions, this integral has a closed-form.\n",
    "\n",
    "Unlike MDL, BDe incorporates prior beliefs and smooths parameter estimates, which can stabilize inference in low-data regimes but may also reduce sensitivity to subtle structural differences.\n",
    "\n",
    "By comparing MDL and BDe, we assess whether observed reconstruction effects are driven primarily by data properties or by the inductive bias of the scoring function.\n",
    "\n",
    "One caveat is that our implementation of those functions is simplified compared to implemented in BNfinder, which may lead to differences in absolute performance. However, relative trends should remain consistent.\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation Metrics\n",
    "Reconstruction quality is evaluated using structure-based graph distance measures. Each metric captures a distinct notion of discrepancy between the true network $G^\\ast$ and the inferred network $\\hat{G}$. \n",
    "\n",
    "**Adjusted Hamming Distance (AHD)**\n",
    "\n",
    "Let $A^\\ast$ and $\\hat{A}$ denote the adjacency matrices of $G^\\ast$ and $\\hat{G}$. The adjusted Hamming distance is defined as\n",
    "\n",
    "$$\n",
    "\\mathrm{AHD}(G^\\ast, \\hat{G})\n",
    "= \\frac{1}{|E^\\ast| + |\\hat{E}|}\n",
    "\\sum_{i,j} \\mathbf{1}_{{A^\\ast_{ij} \\neq \\hat{A}_{ij}}}.\n",
    "$$\n",
    "AHD measures the proportion of mismatched edges, normalized by graph size. It penalizes false positives and false negatives symmetrically and allows comparisons across networks of different sizes. This metric serves as the primary measure of structural accuracy.\n",
    "\n",
    "**Structural Hamming Distance (SHD)**\n",
    "\n",
    "SHD counts the minimum number of edge insertions, deletions, or reversals required to transform $\\hat{G}$ into $G^\\ast$.\n",
    "$\n",
    "\\mathrm{SHD}(G^\\ast, \\hat{G}) \\in \\mathbb{N}.\n",
    "$\n",
    "While widely used, SHD aggregates heterogeneous error types and does not distinguish between missing, extra, or misoriented edges, limiting its interpretability.\n",
    "\n",
    "**Structural Intervention Distance (SID)**\n",
    "\n",
    "SID measures the number of node pairs $(i,j)$ for which the causal effect of intervening on $i$ differs between $G^\\ast$ and $\\hat{G}$.\n",
    "\n",
    "$$\n",
    "\\mathrm{SID}(G^\\ast, \\hat{G})\n",
    "= \\left| {(i,j) : P(j \\mid \\mathrm{do}(i))*{G^\\ast}\n",
    "\\neq P(j \\mid \\mathrm{do}(i))*{\\hat{G}} } \\right|.\n",
    "$$\n",
    "Where $\\mathrm{do}(i=n)$ set node $i$ to have value $n$ at time step, regardles of Boolean update rule.\n",
    "\n",
    "SID is sensitive to edge orientation and captures errors that affect causal interpretability, even when the undirected structure is largely correct.\n",
    "\n",
    "Using these metrics jointly allows us to separate purely topological accuracy (AHD, SHD) from correctness of implied causal relationships (SID) and to identify metric-specific effects of sampling and model selection.\n",
    "\n",
    "---\n",
    "### Independence\n",
    "To avoid introducing structural bias, Boolean networks are generated randomly for each condition:\n",
    "- each node is assigned a random number of parents (uniformly chosen from $\\{ 1 ,2 ,3 \\}$),\n",
    "- Boolean update functions are sampled randomly.\n",
    "All generated networks are accepted without filtering. Repetitions under identical conditions are treated as independent realizations.\n",
    "### Sample Size Normalization\n",
    "To ensure comparability across networks of different sizes, we introduce **sample-size normalization**.\n",
    "Let:\n",
    "- nnodesn_{\\text{nodes}}nnodes​ denote the number of nodes,\n",
    "- TlengthT_{\\text{length}}Tlength​ the trajectory length,\n",
    "- kkk a normalization constant.\n",
    "The total number of sampled time points is defined as:\n",
    "$$\n",
    "\\begin{align}\n",
    "T_{\\text{amount}} & = \\frac{{n_{\\text{nodes}} \\cdot k}}{T_{\\text{length}}} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We fix $k=100$. This choice is motivated by the fact that each node with at most three parents has up to $2^3 = 8$ possible parent-state configurations. Setting $k=100$ corresponds to approximately 10 observations per configuration per node, providing a conservative buffer against stochastic effects and subsampling losses.\n",
    "\n",
    "### Dataset Construction\n",
    "#### General Settings\n",
    "Across all experiments, we vary the following parameters:\n",
    "* number of nodes (`num_nodes`): ([5, 7, 11, 13, 15]),\n",
    "* scoring function (`score_function`): MDL, BDe,\n",
    "* update mode (`update_mode`): synchronous, asynchronous,\n",
    "* parent count per node: randomly chosen from ({1,2,3}),\n",
    "* number of repetitions per condition: 30.\n",
    "---\n",
    "#### Dataset 1 (Baseline Dataset)\n",
    "This dataset is used in Experiments 1 and 2.\n",
    "* trajectory length (`trajectory_length`): ([10, 15, 20, 30, 40, 50]),\n",
    "* sampling frequency (`sampling_frequency`): ([1, 2, 3, 4, 5]),\n",
    "* number of trajectories: determined via sample-size normalization.\n",
    "---\n",
    "#### Dataset 1.1 (Low-Data Regime)\n",
    "To probe behavior in extreme data-scarce settings, an auxiliary dataset is constructed with:\n",
    "* trajectory length: ([5, 7, 9]),\n",
    "* number of nodes: ([5, 7, 9]),\n",
    "* sampling frequency: ([1, 2, 3, 4, 5]).\n",
    "This dataset is included to assess scaling behavior when normalization constraints are tight.\n",
    "---\n",
    "#### Dataset 2 (Normalization Study)\n",
    "Using optimal parameters identified in Experiments 1 and 2, we fix:\n",
    "\n",
    "$$\\begin{align*} \\text{sampling frequency} & =\\begin{cases}1  & \\text{synchronous} \\\\ 4 & \\text{asynchronous}\\end{cases} & \\mathrm{trajectory\\ length}=[0.8 \\cdot x]_{\\mathrm{round}}\\end{align*}$$\n",
    "\n",
    "We then vary the normalization constant:\n",
    "$$k \\in \\{20, 40, 60, 80, 100, 120, 140\\}$$\n",
    "\n",
    "---\n",
    "### Experiments\n",
    "#### Experiment 1: Attractor Prevalence and Trajectory Length\n",
    "Motivated by prior observations that attractor-heavy datasets degrade reconstruction quality, we investigate:\n",
    "1. the correlation between attractor fraction and reconstruction metrics,\n",
    "2. how attractor prevalence depends on trajectory length,\n",
    "3. how these effects scale with network size.\n",
    "We introduce the **scale ratio**\n",
    "$$\\text{scale ratio} = \\frac{T_{\\text{length}}}{n_{\\text{nodes}}}$$\n",
    "and analyze its relationship with attractor fraction to identify regimes that balance coverage of transient dynamics and attractor exploration.\n",
    "\n",
    "---\n",
    "#### Experiment 2: Subsampling and Temporal Dependence\n",
    "This experiment examines whether there exists relation between ESS and metrics score functions subsampling improves reconstruction quality by reducing temporal dependence.\n",
    "We first analyze:\n",
    "* **effective sample size (ESS)**,\n",
    "* **autocorrelation factor (ACF)**,\n",
    "as functions of update mode and sampling frequency.\n",
    "We then assess monotonic relationships between ESS and reconstruction metrics using Spearman correlation. Statistical significance of performance differences between sampling frequencies is evaluated using paired Wilcoxon tests, applied only when sufficient paired observations are available.\n",
    "To avoid confounding effects scale ratios below 1.5 are excluded and cases without effective subsampling are removed.\n",
    "---\n",
    "#### Experiment 3: Normalization and Information Saturation\n",
    "Fixing sampling parameters based on earlier results, we analyze how reconstruction metrics evolve as a function of the normalization constant (k). This allows us to identify saturation regimes in which increasing sample size yields diminishing returns.\n",
    "\n",
    "---\n",
    "#### Experiment 4: Score Function Sensitivity\n",
    "Finally, using a subset of Experiment 3 with fixed normalization, we investigate how reconstruction metrics depend on the choice of scoring function. The goal is to understand whether differences in reconstruction quality arise from data properties or from intrinsic characteristics of the scoring criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddc7c7",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938408a",
   "metadata": {},
   "source": "### Experiment 1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Determinants of Reconstruction Accuracy\n",
    "\n",
    "The primary objective of this analysis was to identify the key factors influencing the accuracy of Boolean network reconstruction using dynamic Bayesian networks (DBNs). Specifically, we investigated how properties of the generated data (attractor ratio, trajectory length), network characteristics (number of nodes), and inference configuration (update mode and scoring function) affect reconstruction quality as measured by standard performance metrics.\n",
    "\n",
    "###### Exploratory Correlation Analysis\n",
    "\n",
    "We first conducted a pairwise correlation analysis between data characteristics and reconstruction metrics (precision, recall, SHD, and AHD)."
   ],
   "id": "2c2931bda36e6263"
  },
  {
   "cell_type": "code",
   "id": "e2e56a46",
   "metadata": {},
   "source": [
    "df1 = df[df[\"trajectory_length\"]>=10]\n",
    "corr_matrix = df[['attractor_ratio', 'num_nodes', 'trajectory_length', 'precision', 'recall', 'SHD', 'AHD']].corr(method='spearman')\n",
    "g = sns.clustermap(corr_matrix,\n",
    "                   annot=True,\n",
    "                   cmap=\"coolwarm\",\n",
    "                   fmt=\".2f\",\n",
    "                   figsize=(10, 10),\n",
    "                   row_cluster=True,\n",
    "                   col_cluster=True,\n",
    "                   center=0,\n",
    "                   dendrogram_ratio=0.1,\n",
    "                   cbar_pos=(0.02, 0.8, 0.03, 0.18))\n",
    "g.ax_heatmap.set_title(\"Clustered Correlation Matrix\", fontsize=16, pad=20)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This exploratory step revealed several notable relationships:\n",
    "\n",
    "- **Attractor ratio** exhibited a strong negative correlation with recall (r = –0.47), indicating that datasets dominated by attractor states substantially impair the recovery of true regulatory interactions.\n",
    "- **Network size (number of nodes)** showed a strong positive correlation with SHD (r = 0.63), confirming that reconstruction error increases with network complexity.\n",
    "- **Trajectory length** displayed near-zero correlations with all performance metrics, suggesting that its effect is not uniform and likely depends on interactions with other factors.\n",
    "\n",
    "These findings suggested that both data composition and network scale play important roles in reconstruction performance, motivating a multivariate analysis to disentangle their independent effects.\n",
    "\n",
    "---\n",
    "\n",
    "### Multivariate Regression Analysis\n",
    "\n",
    "To quantify the independent contribution of each factor while controlling for others, we fitted ordinary least squares (OLS) regression models for structural error (SHD) and adjacency error (AHD). The primary model for SHD included attractor ratio, trajectory length, number of nodes, update mode, scoring function, and an interaction between attractor ratio and trajectory length:\n",
    "\n",
    "```\n",
    "SHD ~ attractor_ratio × trajectory_length + num_nodes + update_mode + score_function\n",
    "```\n"
   ],
   "id": "4527edfe1a28ecf1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbfe326",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(\n",
    "    \"SHD ~ attractor_ratio * trajectory_length + num_nodes + update_mode + score_function\",\n",
    "    data=df\n",
    ").fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The model explained approximately 44% of the variance in SHD (R² ≈ 0.44), indicating substantial explanatory power. The following effects were statistically significant:\n",
    "\n",
    "- **Attractor ratio** had a strong positive effect on SHD, demonstrating that a higher proportion of attractor states in the data leads to increased structural reconstruction error.\n",
    "- **Update mode** (synchronous vs. asynchronous) exerted a large effect, with synchronous updates yielding significantly higher error. This result was expected, as synchronous dynamics reduce the diversity of observable transitions, effectively decreasing the informational content of the data.\n",
    "- **Scoring function** had a strong effect, with MDL outperforming BDe in terms of lower structural error.\n",
    "- **Trajectory length** had a smaller but statistically significant effect on SHD, indicating that longer trajectories do not necessarily improve reconstruction accuracy under fixed sample size conditions.\n",
    "\n",
    "---\n",
    "\n",
    "### Interaction Effects and Mechanistic Insight\n",
    "\n",
    "To further investigate how data characteristics interact, we fitted a second regression model for adjacency error (AHD) including the interaction term:\n",
    "\n",
    "```\n",
    "AHD ~ attractor_ratio × trajectory_length + num_nodes + update_mode + score_function\n",
    "```"
   ],
   "id": "28ee1a323e71986f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = smf.ols(\n",
    "    \"AHD ~ attractor_ratio * trajectory_length + num_nodes + update_mode + score_function\",\n",
    "    data=df\n",
    ").fit()\n",
    "print(model2.summary())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This model revealed a significant negative interaction between attractor ratio and trajectory length, indicating that longer trajectories partially mitigate the detrimental effect of high attractor dominance. In other words, while attractor-heavy datasets are generally less informative, increasing trajectory length can partially compensate by providing more opportunities to observe transient dynamics.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Determinants\n",
    "\n",
    "Overall, reconstruction accuracy was primarily influenced by:\n",
    "\n",
    "1. **Update mode**, which strongly affected performance due to differences in the stochasticity and informational richness of the generated trajectories. This effect is intuitive, as reduced dynamical variability limits the ability to infer causal relationships.\n",
    "2. **Scoring function**, with MDL consistently outperforming BDe under the studied conditions.\n",
    "3. **Attractor ratio**, which emerged as the most influential data-related factor, particularly impairing recall and increasing structural error.\n",
    "4. **Network size**, which substantially increased structural error due to scaling complexity.\n",
    "5. **Trajectory length**, which had a secondary, interaction-dependent effect rather than a uniform influence.\n",
    "\n",
    "These findings demonstrate that reconstruction accuracy is jointly determined by data composition, network complexity, and inference configuration, with attractor dominance playing a central role in limiting the informativeness of time-series data.\n",
    "\n"
   ],
   "id": "a8bd50e781ff29c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing the Impact of Attractor Ratio on Reconstruction Error\n",
    "\n",
    "To complement our regression analysis and gain an intuitive understanding of how **attractor dominance interacts with scoring function and update mode**, we generated scatter plots of **SHD, AHD, BDe and MDL versus attractor ratio**, stratified by **synchronous and asynchronous updates**."
   ],
   "id": "3c666ddb673363b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3bf3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_colors = ['#C0392B', '#2980B9', '#27AE60', '#F4D03F', '#8E44AD']\n",
    "\n",
    "plot_scatter_subplots(df1, x='attractor_ratio', y='SHD', title='SHD vs Attractor Ratio by Update Mode')\n",
    "plot_scatter_subplots(df1, x='attractor_ratio', y='AHD', title='AHD vs Attractor Ratio by Update Mode')\n",
    "plot_scatter_subplots(df1, x='attractor_ratio', y='BDe', title='BDE vs Attractor Ratio by Update Mode')\n",
    "plot_scatter_subplots(df1, x='attractor_ratio', y='MDL', title='MDL vs Attractor Ratio by Update Mode')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Results:\n",
    "\n",
    "* In the **SHD plots**, under **synchronous updates**, most points are clustered at **high attractor ratios (>0.6)**, with SHD ranging broadly from **0 to 40**, reflecting the substantial structural error associated with attractor-dominated datasets. In contrast, **asynchronous updates** show attractor ratios spanning the full range, but SHD is generally much lower for low attractor ratio trajectories, increasing gradually up to **~15** and then **~10**, confirming that asynchronous dynamics produce more informative trajectories.\n",
    "* For **AHD**, synchronous updates again concentrate at **attractor ratios >0.6**, with AHD ranging between **0.1–0.8**, whereas asynchronous updates cover the full attractor range but exhibit a dense cluster near **0–0.4**, indicating overall lower adjacency errors compared to synchronous dynamics.\n",
    "* For **BDe**, synchronous updates concentrate mostly at **attractor ratios >0.6, with BDe ranging between 0.0-1500**. In asynchronous updates, however, a downward trend in BDe can be observed for the atraktor_ratio range of 0.0-0.4. After that, most of the values ​​accumulate close to zero.\n",
    "* For **MDE** the situation was identical to that for BDe.\n",
    "\n",
    "Together, these scatter plots visually confirm our earlier findings: **high attractor ratios are associated with greater reconstruction errors**, and the **update mode strongly shapes the distribution of errors**, with asynchronous updates producing generally more accurate reconstructions. These visualizations provide a bridge to investigating **which factors influence attractor prevalence**, a key driver of reconstruction difficulty.\n",
    "\n",
    "**This observation motivates the next step of our study: since attractor ratio is a key driver of reconstruction error, we now investigate which network- and data-generating factors determine the prevalence of attractor states in Boolean network trajectories.**"
   ],
   "id": "2f05caca51be42d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 1. Relation Between Trajectory Length and Entering Attractors\n",
    "\n",
    "**Objective.**\n",
    "To characterize how trajectory length is related to the probability of entering attractors as a function of network size and dynamics.\n",
    "\n",
    "**Experimental design.**\n",
    "\n",
    "- The target attractor proportion is **not controlled**; trajectories evolve naturally.\n",
    "- Trajectory lengths are varied in increments proportional to network size:\n",
    "    - from 10 steps to 50 by 10\n",
    "- Networks are grouped by size (from 4 to 16 nodes, in steps of two).\n",
    "- The number of parents per node is randomly chosen from set of $\\{1,2,3\\}$ to avoid conditioning results on a fixed connectivity pattern.\n",
    "\n",
    "**Measured quantities.**\n",
    "\n",
    "- Probability of reaching an attractor as a function of trajectory length.\n",
    "- How different groups (below TODO - inner link) differ in in this probability.\n",
    "\n",
    "**Rationale.**\n",
    "Attractor entry is an emergent property of the dynamics. Controlling it directly is undesirable, as it would introduce selection bias. This experiment instead characterizes the **natural scaling behavior** of Boolean network dynamics.\n"
   ],
   "id": "ed5d696db7083a86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "category_colors = ['#C0392B', '#2980B9', '#27AE60', '#F4D03F', '#8E44AD']\n",
    "\n",
    "df_synchronous = df1[df1[\"update_mode\"]==\"synchronous\"]\n",
    "df_asynchronous = df1[df1[\"update_mode\"]==\"asynchronous\"]\n",
    "\n",
    "# Boxplot grouped by num_nodes synchronous\n",
    "plot_boxplot(df_synchronous, x='trajectory_length', y='attractor_ratio', hue='num_nodes',\n",
    "             title='Synchronous: Attractor Ratio vs Trajectory Length\\nGrouped by num_nodes')\n",
    "# Boxplot grouped by num_nodes synchronous\n",
    "plot_boxplot(df_asynchronous, x='trajectory_length', y='attractor_ratio', hue='num_nodes',\n",
    "             title='Asynchronous: Attractor Ratio vs Trajectory Length\\nGrouped by num_nodes')"
   ],
   "id": "abea2f0977df3a17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Results\n",
    "\n",
    "To further explore the factors influencing attractor prevalence, we generated boxplots of **attractor ratio versus trajectory length**, grouped by **network size (num_nodes)**, separately for **synchronous** and **asynchronous** updates.\n",
    "\n",
    "* **Synchronous updates:** attractor ratios are generally higher across all trajectory lengths, consistent with the expected behavior of synchronous Boolean networks, where simultaneous node updates tend to drive the system more quickly into attractor states.\n",
    "* **Asynchronous updates:** attractor ratios are lower overall and more widely distributed, reflecting the increased variability and longer transient dynamics inherent to asynchronous update schemes.\n",
    "\n",
    "Across both update modes, we observe consistent trends:\n",
    "\n",
    "1. **Trajectory length effect:** attractor ratio tends to increase with longer trajectories.\n",
    "2. **Network size effect:** attractor ratio tends to decrease as the number of nodes increases.\n",
    "\n",
    "These observations visually confirm the patterns suggested by our regression and scatter plot analyses, providing an intuitive view of how **update mode, trajectory length, and network size jointly shape attractor prevalence** in simulated Boolean networks."
   ],
   "id": "55d8cbcccf711ec8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Scaling Law Analysis: Normalizing Trajectory Length by Network Size\n",
    "\n",
    "To systematically compare how trajectory length and network size jointly influence convergence, we introduced a **scaling metric**: the **scale_ratio**, defined as `trajectory_length / num_nodes`. This metric normalizes the simulation time by the network’s complexity, allowing us to identify a unified scaling behavior across different system sizes."
   ],
   "id": "29708eed885ad22f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_summary = (\n",
    "    df\n",
    "    .groupby([\"trajectory_length\", \"num_nodes\"])\n",
    "    .agg(\n",
    "        median_ar=(\"attractor_ratio\", \"median\"),\n",
    "        q25_ar=(\"attractor_ratio\", lambda x: x.quantile(0.25)),\n",
    "        mean_ar=(\"attractor_ratio\", \"mean\"),\n",
    "        std_ar=(\"attractor_ratio\", \"std\"),\n",
    "        n=(\"attractor_ratio\", \"size\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_summary[\"scale_ratio\"] = (\n",
    "        df_summary[\"trajectory_length\"] / df_summary[\"num_nodes\"]\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_summary,\n",
    "    x=\"scale_ratio\",\n",
    "    y=\"median_ar\",\n",
    "    hue=\"num_nodes\"\n",
    ")\n",
    "df_summary.head()"
   ],
   "id": "323446890e00db44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "traj_lengths = sorted(df_summary['trajectory_length'].unique())\n",
    "n_cols = 3\n",
    "n_rows = (len(traj_lengths) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows), sharey=True)\n",
    "axes = axes.flatten()\n",
    "for i, traj_len in enumerate(traj_lengths):\n",
    "    ax = axes[i]\n",
    "    df_sub = df_summary[df_summary['trajectory_length'] == traj_len]\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=df_sub,\n",
    "        x=\"scale_ratio\",\n",
    "        y=\"median_ar\",\n",
    "        hue=\"num_nodes\",\n",
    "        palette=\"tab10\",\n",
    "        s=80,\n",
    "        alpha=0.7,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Trajectory Length = {traj_len}\")\n",
    "    ax.set_xlabel(\"Scale Ratio (trajectory_length / num_nodes)\")\n",
    "    ax.set_ylabel(\"Median Attractor Ratio\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.suptitle(\"Median Attractor Ratio vs Scale Ratio by Trajectory Length\", fontsize=18, y=1.02)\n",
    "plt.show()\n"
   ],
   "id": "94e9bc9c1b1a48ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Results\n",
    "\n",
    "From the subplots of **median attractor ratio (`median_ar`) versus scale ratio (`trajectory_length / num_nodes`)**, several clear patterns emerge:\n",
    "\n",
    "* **Positive relationship with scale ratio:** In general, the median attractor ratio increases as the scale ratio grows. This indicates that networks with relatively longer trajectories compared to their size tend to spend more time in attractor states.\n",
    "* **Effect of trajectory length:** For larger trajectory lengths, the median attractor ratio remains high even for small scale ratios. This suggests that longer trajectories provide more opportunities for the system to reach attractor states, regardless of network size.\n",
    "* **Group-level consistency:** These trends are consistent across different network sizes (`num_nodes`) and are particularly evident in groups with a sufficiently large number of observations, which ensures that the results are statistically robust."
   ],
   "id": "2f7537659453ff9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---- prepare dfs ----\n",
    "dfs_series = dfs.copy()\n",
    "dfs_series[\"scale\"] = dfs_series[\"trajectory_length\"] / dfs_series[\"num_nodes\"]\n",
    "dfs_series[\"trajectories_per_node\"] = dfs_series[\"n_trajectories\"] / dfs_series[\"num_nodes\"]\n",
    "\n",
    "# filtering\n",
    "dfs_series = dfs_series[dfs_series[\"scale\"] < 1.5]\n",
    "dfs_series = dfs_series[dfs_series[\"trajectory_length\"] > 1]\n",
    "\n",
    "# ---- prepare dfa ----\n",
    "dfa_series = dfa.copy()\n",
    "dfa_series[\"scale\"] = dfa_series[\"trajectory_length\"] / dfa_series[\"num_nodes\"]\n",
    "dfa_series[\"trajectories_per_node\"] = dfa_series[\"n_trajectories\"] / dfa_series[\"num_nodes\"]\n",
    "\n",
    "# filtering\n",
    "dfa_series = dfa_series[dfa_series[\"scale\"] < 1.5]\n",
    "dfa_series = dfa_series[dfa_series[\"trajectory_length\"] > 1]\n",
    "\n",
    "dfs['update_mode'] = 'synchronous'\n",
    "dfa['update_mode'] = 'asynchronous'\n",
    "\n",
    "dfs['k_value'] = dfs['trajectory_length'] / dfs['num_nodes']\n",
    "dfa['k_value'] = dfa['trajectory_length'] / dfa['num_nodes']\n",
    "\n",
    "dfs['k_value'] = dfs['trajectory_length'] / dfs['num_nodes']\n",
    "dfa['k_value'] = dfa['trajectory_length'] / dfa['num_nodes']\n",
    "\n",
    "# sprawdzamy jakie unikalne wartości masz\n",
    "dfs['k_value'] = dfs['k_value'].round(3)\n",
    "dfa['k_value'] = dfa['k_value'].round(3)\n",
    "\n",
    "k_vals_s = sorted(dfs['k_value'].dropna().unique())\n",
    "print(k_vals_s)\n",
    "# [0.769, 0.778, 0.8, 0.818, 0.857]\n",
    "\n",
    "\n",
    "transitions_s = [(k_vals_s[i], k_vals_s[i + 1]) for i in range(len(k_vals_s) - 1)]\n",
    "print(transitions_s)\n",
    "print(dfs.columns)"
   ],
   "id": "82c652442f3a7c1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(dfs.columns)\n",
    "df_wilcoxon_s = compute_wilcoxon_table(\n",
    "    dfs,\n",
    "    metrics=[\"AHD\", \"SHD\"],\n",
    "    transitions=transitions_s,\n",
    "    sf_col='k_value'\n",
    ")\n",
    "\n",
    "print(df_wilcoxon_s)"
   ],
   "id": "dfb828b522c39236"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "plot_wilcoxon_heatmap(\n",
    "    df_wilcoxon_a,\n",
    "    metric=\"AHD\",\n",
    "    update_mode=\"asynchronous\",\n",
    "    transitions_order=[\"20→40\", \"40→60\", \"60→80\", \"80→100\"],\n",
    "    ax=axes[0],\n",
    "    cbar=False\n",
    ")\n",
    "\n",
    "plot_wilcoxon_heatmap(\n",
    "    df_wilcoxon_a,\n",
    "    metric=\"SID\",\n",
    "    update_mode=\"asynchronous\",\n",
    "    transitions_order=[\"20→40\", \"40→60\", \"60→80\", \"80→100\"],\n",
    "    ax=axes[1],\n",
    "    cbar=True\n",
    ")\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Paired Wilcoxon test: effect of increasing number of trajectories\\n\"\n",
    "    \"Asynchronous update\",\n",
    "    fontsize=18,\n",
    "    y=1.05\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "57e357ab0b9046ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment 2",
   "id": "37b0a9a044b276b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Global parameters\n",
    "NUM_NODES = [i for i in range(5, 17, 2)]  # od 5 do 15 (włącznie) wierzchołków, co dwie krawędzie\n",
    "SCORE_FUNCTIONS = [\"MDL\", \"BDE\"]\n",
    "UPDATE_MODE = [\"synchronous\", \"asynchronous\"]\n",
    "N_PARENT_PER_NODE = [[1, 2, 3]]\n",
    "N_REPETITIONS = 30"
   ],
   "id": "cdbbebc07fa737a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create experiments:\n",
    "## case: Relation between trajectory length and entering attractors\n",
    "exp_trajectory_length = BooleanNetworkExperiment(\n",
    "    ### paths\n",
    "    data_path=DATA_PATH,\n",
    "    experiment_name='trajectory_length_vs_attractors',\n",
    "\n",
    "    ### Tested variables\n",
    "    trajectory_length=[10, 15, 20, 30, 40, 50],\n",
    "    n_trajectories=[100],\n",
    "    sampling_frequency=[1, 2, 3, 4, 5],\n",
    "\n",
    "    ### Constant values per experiment\n",
    "    n_repetitions=30,\n",
    "    n_parents_per_node=N_PARENT_PER_NODE,\n",
    "\n",
    "    ### Groups (bo wszędzie takie same)\n",
    "    num_nodes=NUM_NODES,\n",
    "    score_functions=SCORE_FUNCTIONS,\n",
    "    update_mode=UPDATE_MODE,\n",
    "\n",
    "    simulate_trajectories_to_csv_kwargs={\n",
    "        # \"sampling_frequency\": 1,\n",
    "        \"target_attractor_ratio\": 0.5,  # Approximate fraction of trajectory in attractor (0-1)\n",
    "        \"tolerance\": 0.125,  # Allowed deviation from the calculated entrance step (0-1)\n",
    "    }\n",
    ")\n",
    "# standardize sample\n",
    "exp_trajectory_length.normalize_sample(100)  # WAŻNE NORMALIZUJE PRÓBĘ\n",
    "exp_trajectory_length.show_experiment_df()\n",
    "\n",
    "exp_trajectory_length.run_experiment(n_jobs=1)\n"
   ],
   "id": "9accec48595abcd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 2. Impact of Sampling Frequency\n",
    "\n",
    "**Objective.**\n",
    "To determine how temporal subsampling affects autocorrelation, effective sample size, and reconstruction accuracy.\n",
    "\n",
    "Dynamic Bayesian network inference assumes conditional independence of observations given parent states in the previous time slice. Excessive temporal dependence violates this assumption in practice by introducing redundant observations.\n",
    "\n",
    "**Experimental design.**\n",
    "\n",
    "- For fixed networks and trajectory lengths, datasets are generated using multiple sampling frequencies (1, 2, 3, 4, 5).\n",
    "- For each dataset\n",
    "    - ACF and ESS are computed,\n",
    "    - MDL and BDe scores are extracted from BNFinder2 logs,\n",
    "\n",
    "**Analysis.**\n",
    "Accuracy is analyzed jointly as a function of:\n",
    "<!-- What does it mean jointly ?? -->\n",
    "\n",
    "* sampling frequency,\n",
    "* ESS,\n",
    "* scoring function (MDL or BDe).\n",
    "\n",
    "**Rationale.**\n",
    "This experiment identifies sampling regimes that balance reduced autocorrelation against loss of dynamic information due to over-subsampling.\n"
   ],
   "id": "a247ff5344746f6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment 3",
   "id": "2b3d41c8b7d000b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 3. Amount of Trajectories Required for Stable Inference\n",
    "\n",
    "**Objective.**\n",
    "To determine how many independent trajectories are required to obtain statistically stable reconstructions.\n",
    "\n",
    "**Experimental design.**\n",
    "\n",
    "- Sampling frequency and trajectory length are fixed to values identified as near-optimal in previous experiments.\n",
    "- The number of trajectories per dataset is gradually increased - from 10 to 100 by 10.\n",
    "- For each setting, multiple (30) independent repetitions are performed to obtain convergent distribution .\n",
    "\n",
    "**Evaluation.**\n",
    "\n",
    "- Reconstruction accuracy is summarized using distributions (score functions).\n",
    "- Stability is assessed by observing convergence of accuracy metrics as the number of trajectories increases.\n",
    "- No classical parametric hypothesis test is assumed; instead, convergence trends is reported.\n",
    "<!-- Nie znalazłem żadnego sensownego -->\n",
    "\n",
    "**Rationale.**\n",
    "Due to the randomness of Boolean functions and initial states, averaging over multiple networks is necessary to separate systematic effects from instance-specific variability.\n"
   ],
   "id": "a1d4debe944558b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create experiments:\n",
    "## case: Relation between trajectory length and entering attractors\n",
    "exp_trajectory_length = BooleanNetworkExperiment(\n",
    "    ### paths\n",
    "    data_path=DATA_PATH,\n",
    "    experiment_name='trajectory_length_vs_attractors',\n",
    "\n",
    "    ### Tested variables\n",
    "    trajectory_length=list(30),\n",
    "    n_trajectories=[50],\n",
    "    sampling_frequency=[1],\n",
    "\n",
    "    ### Constant values per experiment\n",
    "    n_repetitions=N_REPETITIONS,\n",
    "    n_parents_per_node=N_PARENT_PER_NODE,\n",
    "\n",
    "    ### Groups (bo wszędzie takie same)\n",
    "    num_nodes=NUM_NODES,\n",
    "    score_functions=SCORE_FUNCTIONS,\n",
    "    update_mode=UPDATE_MODE,\n",
    "\n",
    "    simulate_trajectories_to_csv_kwargs={\n",
    "        # \"sampling_frequency\": 1,\n",
    "        \"target_attractor_ratio\": 0.5,  # Approximate fraction of trajectory in attractor (0-1)\n",
    "        \"tolerance\": 0.5,  # Allowed deviation from the calculated entrance step (0-1)\n",
    "    }\n",
    ")\n",
    "exp_trajectory_length.show_experiment_df()"
   ],
   "id": "9221e99b615b8c17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3cf62a11907f290"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment 4",
   "id": "8f6e321f6246e773"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 2",
   "id": "0a0ff7f7"
  },
  {
   "cell_type": "markdown",
   "id": "415e8ead",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbf2cd",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a04cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sad2-final-project (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
