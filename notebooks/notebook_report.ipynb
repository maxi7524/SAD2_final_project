{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d758ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sad2_final_project.analysis import add_missing_metrics_from_experiment, loader_obsolete_data\n",
    "import os\n",
    "from sad2_final_project.analysis import plot_scatter, plot_boxplot, plot_scatter_subplots\n",
    "\n",
    "# paths\n",
    "## set global dir\n",
    "cwd=Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    os.chdir(cwd.parent) \n",
    "print(os.getcwd())\n",
    "## create paths \n",
    "DATA_PATH2 = Path('data/trajectory_length_vs_attractors1')\n",
    "\n",
    "df = loader_obsolete_data(DATA_PATH2 / 'results/metadata.csv', DATA_PATH2 / 'results/joined_results_trajectory_length_vs_attractors.csv')\n",
    "metrics_list=['TP', 'FP', 'FN', 'precision', 'recall', 'sensitivity', 'AHD', 'SHD', 'EHD', 'SID']\n",
    "df = add_missing_metrics_from_experiment(df, DATA_PATH2, metrics_list, after_column='attractor_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc401a88",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "## Goal\n",
    "The goal of this study is to investigate the relation between **sampling strategy** and **model selection metrics** in *boolean Bayesian networks (BDNs)* using `BNFinder2`. \n",
    "\n",
    "In particular, we analyze how characteristics of time-series data generated from Boolean networks influence the accuracy of reconstructing the underlying network structure using Bayesian methods. The experimental factors under investigation include:\n",
    "- the **trajectory length**,\n",
    "- the **sampling frequency**, defined as selecting every $n$-th state along a trajectory,\n",
    "- the ratio between the **number of nodes** and the **trajectory length**, introduced as a normalization parameter $k$.\n",
    "\n",
    "The generated datasets are grouped into classes determined by:\n",
    "- the **update mode** (synchronous vs asynchronous),\n",
    "- the **scoring function** used during inference (MDL and BDe).\n",
    "\n",
    "In addition, we study **scaling relations with respect to the number of nodes**, aiming to characterize how data requirements and reconstruction accuracy change as network size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c639ad",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487eda0",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "### General reasoning \n",
    "The primary objective of the experimental design is to isolate how properties of sampled time-series data affect the accuracy of Boolean network reconstruction using `BNFinder2`. \n",
    "***\n",
    "### Update Mode\n",
    "We distinguish between two fundamentally different update mechanisms:\n",
    "- **Synchronous update**, which defines a deterministic dynamical system: from any given state, the successor state is uniquely determined.\n",
    "- **Asynchronous update**, which induces a stochastic process: at each time step, a randomly selected node is updated, leading to multiple possible successor states.\n",
    "This distinction is critical, as asynchronous dynamics introduce temporal dependence and potential autocorrelation in trajectories. In particular, long residence times in attractors or local cycles may reduce the effective information content of sampled data. Consequently, naive dense sampling may lead to strongly correlated observations, while aggressive subsampling may destroy causal ordering information.\n",
    "***\n",
    "### Scoring Functions\n",
    "We employ two scoring functions implemented in BNFinder2, which differ in how they trade off data fit against model complexity.\n",
    "Let $G$ denote a candidate network structure and $D$ the observed dataset.\n",
    "\n",
    "**Minimal Description Length (MDL)**\n",
    "\n",
    "The MDL score is defined as\n",
    "$$\n",
    "\\mathrm{MDL}(G \\mid D)\n",
    "= - \\log P(D \\mid G, \\hat{\\theta})\n",
    "\\times \\frac{1}{2} , |\\theta_G| , \\log |D|,\n",
    "$$\n",
    "\n",
    "\n",
    "where $\\hat{\\theta}$ are maximum-likelihood parameters and $|\\theta_G|$ denotes the number of free parameters implied by the graph structure $G$.\n",
    "\n",
    "The first term rewards goodness of fit, while the second term penalizes model complexity. As a consequence, MDL favors simpler graphs when data are scarce and becomes less restrictive as sample size increases. This makes MDL particularly sensitive to undersampling and normalization effects.\n",
    "\n",
    "**Bayesian–Dirichlet equivalence (BDe)**\n",
    "\n",
    "The BDe score evaluates the marginal likelihood\n",
    "\n",
    "$$\n",
    "\\mathrm{BDe}(G \\mid D)\n",
    "= \\log \\int P(D \\mid G, \\theta), P(\\theta \\mid G), d\\theta,\n",
    "$$\n",
    "\n",
    "assuming a Dirichlet prior over conditional probability tables. Under standard assumptions, this integral has a closed-form.\n",
    "\n",
    "Unlike MDL, BDe incorporates prior beliefs and smooths parameter estimates, which can stabilize inference in low-data regimes but may also reduce sensitivity to subtle structural differences.\n",
    "\n",
    "By comparing MDL and BDe, we assess whether observed reconstruction effects are driven primarily by data properties or by the inductive bias of the scoring function.\n",
    "\n",
    "One caveat is that our implementation of those functions is simplified compared to implemented in BNfinder, which may lead to differences in absolute performance. However, relative trends should remain consistent.\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation Metrics\n",
    "Reconstruction quality is evaluated using structure-based graph distance measures. Each metric captures a distinct notion of discrepancy between the true network $G^\\ast$ and the inferred network $\\hat{G}$. \n",
    "\n",
    "**Adjusted Hamming Distance (AHD)**\n",
    "\n",
    "Let $A^\\ast$ and $\\hat{A}$ denote the adjacency matrices of $G^\\ast$ and $\\hat{G}$. The adjusted Hamming distance is defined as\n",
    "\n",
    "$$\n",
    "\\mathrm{AHD}(G^\\ast, \\hat{G})\n",
    "= \\frac{1}{|E^\\ast| + |\\hat{E}|}\n",
    "\\sum_{i,j} \\mathbf{1}_{{A^\\ast_{ij} \\neq \\hat{A}_{ij}}}.\n",
    "$$\n",
    "AHD measures the proportion of mismatched edges, normalized by graph size. It penalizes false positives and false negatives symmetrically and allows comparisons across networks of different sizes. This metric serves as the primary measure of structural accuracy.\n",
    "\n",
    "**Structural Hamming Distance (SHD)**\n",
    "\n",
    "SHD counts the minimum number of edge insertions, deletions, or reversals required to transform $\\hat{G}$ into $G^\\ast$.\n",
    "$\n",
    "\\mathrm{SHD}(G^\\ast, \\hat{G}) \\in \\mathbb{N}.\n",
    "$\n",
    "While widely used, SHD aggregates heterogeneous error types and does not distinguish between missing, extra, or misoriented edges, limiting its interpretability.\n",
    "\n",
    "**Structural Intervention Distance (SID)**\n",
    "\n",
    "SID measures the number of node pairs $(i,j)$ for which the causal effect of intervening on $i$ differs between $G^\\ast$ and $\\hat{G}$.\n",
    "\n",
    "$$\n",
    "\\mathrm{SID}(G^\\ast, \\hat{G})\n",
    "= \\left| {(i,j) : P(j \\mid \\mathrm{do}(i))*{G^\\ast}\n",
    "\\neq P(j \\mid \\mathrm{do}(i))*{\\hat{G}} } \\right|.\n",
    "$$\n",
    "Where $\\mathrm{do}(i=n)$ set node $i$ to have value $n$ at time step, regardles of Boolean update rule.\n",
    "\n",
    "SID is sensitive to edge orientation and captures errors that affect causal interpretability, even when the undirected structure is largely correct.\n",
    "\n",
    "Using these metrics jointly allows us to separate purely topological accuracy (AHD, SHD) from correctness of implied causal relationships (SID) and to identify metric-specific effects of sampling and model selection.\n",
    "\n",
    "---\n",
    "### Independence\n",
    "To avoid introducing structural bias, Boolean networks are generated randomly for each condition:\n",
    "- each node is assigned a random number of parents (uniformly chosen from $\\{ 1 ,2 ,3 \\}$),\n",
    "- Boolean update functions are sampled randomly.\n",
    "All generated networks are accepted without filtering. Repetitions under identical conditions are treated as independent realizations.\n",
    "### Sample Size Normalization\n",
    "To ensure comparability across networks of different sizes, we introduce **sample-size normalization**.\n",
    "Let:\n",
    "- nnodesn_{\\text{nodes}}nnodes​ denote the number of nodes,\n",
    "- TlengthT_{\\text{length}}Tlength​ the trajectory length,\n",
    "- kkk a normalization constant.\n",
    "The total number of sampled time points is defined as:\n",
    "$$\n",
    "\\begin{align}\n",
    "T_{\\text{amount}} & = \\frac{{n_{\\text{nodes}} \\cdot k}}{T_{\\text{length}}} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We fix $k=100$. This choice is motivated by the fact that each node with at most three parents has up to $2^3 = 8$ possible parent-state configurations. Setting $k=100$ corresponds to approximately 10 observations per configuration per node, providing a conservative buffer against stochastic effects and subsampling losses.\n",
    "\n",
    "### Dataset Construction\n",
    "#### General Settings\n",
    "Across all experiments, we vary the following parameters:\n",
    "* number of nodes (`num_nodes`): ([5, 7, 11, 13, 15]),\n",
    "* scoring function (`score_function`): MDL, BDe,\n",
    "* update mode (`update_mode`): synchronous, asynchronous,\n",
    "* parent count per node: randomly chosen from ({1,2,3}),\n",
    "* number of repetitions per condition: 30.\n",
    "---\n",
    "#### Dataset 1 (Baseline Dataset)\n",
    "This dataset is used in Experiments 1 and 2.\n",
    "* trajectory length (`trajectory_length`): ([10, 15, 20, 30, 40, 50]),\n",
    "* sampling frequency (`sampling_frequency`): ([1, 2, 3, 4, 5]),\n",
    "* number of trajectories: determined via sample-size normalization.\n",
    "---\n",
    "#### Dataset 1.1 (Low-Data Regime)\n",
    "To probe behavior in extreme data-scarce settings, an auxiliary dataset is constructed with:\n",
    "* trajectory length: ([5, 7, 9]),\n",
    "* number of nodes: ([5, 7, 9]),\n",
    "* sampling frequency: ([1, 2, 3, 4, 5]).\n",
    "This dataset is included to assess scaling behavior when normalization constraints are tight.\n",
    "---\n",
    "#### Dataset 2 (Normalization Study)\n",
    "Using optimal parameters identified in Experiments 1 and 2, we fix:\n",
    "\n",
    "$$\\begin{align*} \\text{sampling frequency} & =\\begin{cases}1  & \\text{synchronous} \\\\ 4 & \\text{asynchronous}\\end{cases} & \\mathrm{trajectory\\ length}=[0.8 \\cdot x]_{\\mathrm{round}}\\end{align*}$$\n",
    "\n",
    "We then vary the normalization constant:\n",
    "$$k \\in \\{20, 40, 60, 80, 100, 120, 140\\}$$\n",
    "\n",
    "---\n",
    "### Experiments\n",
    "#### Experiment 1: Attractor Prevalence and Trajectory Length\n",
    "Motivated by prior observations that attractor-heavy datasets degrade reconstruction quality, we investigate:\n",
    "1. the correlation between attractor fraction and reconstruction metrics,\n",
    "2. how attractor prevalence depends on trajectory length,\n",
    "3. how these effects scale with network size.\n",
    "We introduce the **scale ratio**\n",
    "$$\\text{scale ratio} = \\frac{T_{\\text{length}}}{n_{\\text{nodes}}}$$\n",
    "and analyze its relationship with attractor fraction to identify regimes that balance coverage of transient dynamics and attractor exploration.\n",
    "\n",
    "---\n",
    "#### Experiment 2: Subsampling and Temporal Dependence\n",
    "This experiment examines whether there exists relation between ESS and metrics score functions subsampling improves reconstruction quality by reducing temporal dependence.\n",
    "We first analyze:\n",
    "* **effective sample size (ESS)**,\n",
    "* **autocorrelation factor (ACF)**,\n",
    "as functions of update mode and sampling frequency.\n",
    "We then assess monotonic relationships between ESS and reconstruction metrics using Spearman correlation. Statistical significance of performance differences between sampling frequencies is evaluated using paired Wilcoxon tests, applied only when sufficient paired observations are available.\n",
    "To avoid confounding effects scale ratios below 1.5 are excluded and cases without effective subsampling are removed.\n",
    "---\n",
    "#### Experiment 3: Normalization and Information Saturation\n",
    "Fixing sampling parameters based on earlier results, we analyze how reconstruction metrics evolve as a function of the normalization constant (k). This allows us to identify saturation regimes in which increasing sample size yields diminishing returns.\n",
    "\n",
    "---\n",
    "#### Experiment 4: Score Function Sensitivity\n",
    "Finally, using a subset of Experiment 3 with fixed normalization, we investigate how reconstruction metrics depend on the choice of scoring function. The goal is to understand whether differences in reconstruction quality arise from data properties or from intrinsic characteristics of the scoring criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddc7c7",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938408a",
   "metadata": {},
   "source": [
    "### Experiment 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e56a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2315ff62",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbfe326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c8f6a20",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb147c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9a45b9b",
   "metadata": {},
   "source": [
    "### Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3bf3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a0ff7f7",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e8ead",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbf2cd",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a04cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sad2-final-project (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
