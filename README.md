
# New

## Initialization 
To use project repository after fork you need to:
1. Synchronize dependencies
```bash
uv sync
```
2. Activate environment
```bash
source .venv/bin/activate
```
3. Install library in development mode
```bash
uv pip install -e .
```
To run `path/script.py` you need to run:
```bash
uv run python path/script
```


# Old
## Articles 

## Programming organization 

### Part 1

The `BN` class handles:

* Boolean network construction (random or user-defined functions),
* synchronous and asynchronous updates,
* trajectory simulation,
* state transition system (STS) generation,
* attractor detection and visualization.

---

#### `simulate_trajectory()` – Notes for Future Development

This method is central to dataset generation and is likely to be extended. Currently, it:

* Starts from a **random initial state**.
* Simulates updates for
  `n = (trajectory_length - 1) * sampling_frequency` steps.
* Samples every `sampling_frequency` steps.
* Returns:

  * the trajectory,
  * number of sampled states in attractors,
  * number of sampled transient states.

---

#### Network Generation

* Boolean functions are either:

  * provided explicitly, or
  * generated randomly with 2–3 parents per node.
* Parent selection and operator choice (`&`, `|`) can be modified for different network topologies or function complexity.

---

#### Attractors & STS

* Attractors are computed from the full state transition system using `networkx.attracting_components`.
* The STS is rebuilt when needed; caching could improve performance for larger networks.

---

### Part 2


# TODO / ideas

## Part I

### **Goal**
- Construction of various Boolean networks  
- Simulation of trajectories generated by these networks  
- Inferring Bayesian networks using **BNFinder2**  
- Evaluation of reconstruction accuracy  

---

### **Construction of Boolean Networks**

Construct several Boolean networks with sizes (measured by the number of nodes or variables) ranging from 5 to 16. Each node should have no more than three parent nodes, and the Boolean functions governing individual nodes should be generated at random.

We can extend the existing `BN` class from lab 4:
- It already handles storing Boolean networks, computing state transitions, identifying attractors, and visualizing the network.
- What still needs to be added:
  1. **Random Boolean network generation**, 
  Function that generates attributes for `BN` class
- ideas of implementation 
  - TODO 

---

### **Simulation of Trajectories**

Simulate trajectories of the generated networks in both synchronous and asynchronous modes to create datasets.  
The datasets should vary in:
1. The proportion of transient and attractor states  
2. The trajectory sampling frequency (i.e., the number of time steps between successive sampled states)  
3. The overall dataset size (i.e., the number and length of trajectories)

We need: method in `BN` class to simulate trajectories satisfying these conditions.

---

### **Inferring Dynamic Bayesian Networks with BNFinder2**

Use the datasets to infer dynamic Bayesian networks using the BNFinder2 software tool.  
Dynamic Bayesian networks allow cycles, making them suitable for reconstructing network structures from temporal data.

Two scoring functions should be considered:
- Minimal Description Length (**MDL**)  
- Bayesian–Dirichlet equivalence (**BDe**)  

We need a class that will:
- Accept dataset files generated in step 2  
- Run BNFinder2 to reconstruct a network  
- Allow choosing between MDL and BDe scoring criteria  

ideas of implementation 
- TODO 

---

##a# **Evaluation**

A separate class will compare the reconstructed networks with the original networks.  
It will measure structural accuracy.

ideas of implementation 
max_proposal_1
  - we can create different metrics as methods, and make some table that connects them in letter / number ids
  - we can create method responsible for making raport, than for given, ids it would calculate those metrics and merge than in one df (we could do multiple different test on every boolean model) 
  
## Part 2 
We need to sort out repositories which relevant, and find models with natural interpretation - we can also compare does it preserved its meaning. 